<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Learn about t-SNE, a dimensionality reduction method. Comprehensive overview with theory, applications, and use cases for machine learning and data science.">
  <link rel="canonical" href="https://yourdomain.com/Dimensionality_Reduction/t-SNE_DR_Overview.html">
  <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "name": "t-SNE - Overview & Theory | Dimensionality Reduction | ML Tools",
  "description": "Learn about t-SNE, a dimensionality reduction method. Comprehensive overview with theory, applications, and use cases for machine learning and data science.",
  "url": "https://yourdomain.com/Dimensionality_Reduction/t-SNE_DR_Overview.html",
  "about": {
    "@type": "Thing",
    "name": "t-SNE",
    "description": "t-SNE algorithm for dimensionality reduction"
  },
  "headline": "t-SNE",
  "articleSection": "Dimensionality Reduction"
}
  </script>
    <title>t-SNE - Overview & Theory | Dimensionality Reduction | ML Tools</title>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@200;300;400;600;700;800;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Nunito', sans-serif;
            color: #cfcfcf;
            background-color: #1e1e1e;
            margin: 0;
            padding: 0;
            display: flex;
            min-height: 100vh;
        }
        .sidebar {
            width: 250px;
            background-color: #171717;
            padding: 30px 20px;
            border-right: 1px solid #333;
            overflow-y: auto;
            height: 100vh;
        }
        .sidebar h1 { color: white; font-size: 1.8rem; font-weight: bold; margin-bottom: 30px; text-align: center; }
        .nav-section { margin-bottom: 30px; }
        .nav-section h3 { color: #dd8448; font-size: 0.9rem; font-weight: 600; text-transform: uppercase; margin-bottom: 15px; letter-spacing: 1px; }
        .nav-item { display: block; color: #676767; text-decoration: none; padding: 12px 15px; margin-bottom: 5px; border-radius: 8px; transition: all 0.3s ease; font-weight: 500; }
        .nav-item:hover { background-color: #2d2d2d; color: white; transform: translateX(5px); }
        .nav-item.active { background-color: #dd8448; color: white; }
        .nav-category { margin-bottom: 20px; }
        .nav-category-header { color: #dd8448; font-size: 0.85rem; font-weight: 600; text-transform: uppercase; padding: 10px 15px; cursor: pointer; border-radius: 8px; transition: background-color 0.3s ease; display: flex; justify-content: space-between; align-items: center; letter-spacing: 1px; }
        .nav-category-header:hover { background-color: #2d2d2d; }
        .nav-category-header .arrow { transition: transform 0.3s ease; font-size: 0.7rem; }
        .nav-category-header.collapsed .arrow { transform: rotate(-90deg); }
        .nav-subcategory { margin-left: 15px; margin-top: 10px; overflow: hidden; max-height: 1200px; transition: max-height 0.3s ease; }
        .nav-subcategory.collapsed { max-height: 0; }
        .nav-subheader { color: #999; font-size: 0.75rem; font-weight: 600; text-transform: uppercase; padding: 8px 15px; margin-top: 5px; letter-spacing: 0.5px; cursor: pointer; display: flex; justify-content: space-between; align-items: center; border-radius: 6px; transition: background-color 0.3s ease; }
        .nav-subheader:hover { background-color: #2d2d2d; }
        .nav-subheader .arrow { font-size: 0.6rem; transition: transform 0.3s ease; }
        .nav-subheader.collapsed .arrow { transform: rotate(-90deg); }
        .nav-subheader.category-header { color: #dd8448; font-size: 0.85rem; font-weight: 700; padding: 10px 15px; margin-top: 8px; letter-spacing: 1px; border: 1px solid rgba(221,132,72,0.3); }
        .nav-subheader.category-header:hover { background-color: rgba(221,132,72,0.15); border-color: rgba(221,132,72,0.5); }
        .nav-subgroup { overflow: hidden; max-height: 200px; transition: max-height 0.3s ease; padding-bottom: 5px; }
        .nav-subgroup.collapsed { max-height: 0; }
        .nav-subgroup.category-group { max-height: 1000px; }
        .nav-subgroup.category-group.collapsed { max-height: 0; }
        .nav-subheader.nested { margin-left: 10px; font-size: 0.7rem; }
        .nav-subgroup.nested { margin-left: 10px; max-height: 200px; }
        .nav-subheader.subcategory-header { color: #999; font-size: 0.75rem; font-weight: 600; padding: 8px 15px; margin-left: 10px; margin-top: 5px; letter-spacing: 0.5px; border: 1px solid rgba(153, 153, 153, 0.2); }
        .nav-subheader.subcategory-header:hover { background-color: rgba(45, 45, 45, 0.5); border-color: rgba(153, 153, 153, 0.4); }
        .nav-subgroup.subcategory-group { margin-left: 10px; max-height: 2000px; overflow: hidden; transition: max-height 0.3s ease; padding-bottom: 5px; }
        .nav-subgroup.subcategory-group.collapsed { max-height: 0; }
        .nav-item.sub { padding: 8px 15px; font-size: 0.9rem; margin-left: 10px; margin-bottom: 5px; }
        .main-content {
            flex: 1;
            padding: 40px;
        }
        .title {
            color: #ffffff;
            font-size: 2.2rem;
            font-weight: 800;
            margin: 0 0 8px 0;
        }
        .subtitle {
            color: #8a8a8a;
            font-size: 1rem;
            margin-bottom: 28px;
        }
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 20px;
            margin-bottom: 28px;
        }
        .card {
            background-color: #171717;
            border: 1px solid #333;
            border-radius: 12px;
            padding: 22px;
            transition: border-color 0.3s ease, transform 0.3s ease;
        }
        .card:hover { border-color: #dd8448; transform: translateY(-3px); }
        .card h3 { color: #ffffff; margin: 0 0 8px 0; font-size: 1.15rem; }
        .card p { color: #9a9a9a; margin: 0; line-height: 1.6; }
        .section {
            background-color: #171717;
            border: 1px solid #333;
            border-radius: 12px;
            padding: 24px;
            margin-bottom: 24px;
        }
        .section h2 {
            color: #ffffff;
            font-size: 1.5rem;
            margin: 0 0 12px 0;
        }
        .badge {
            display: inline-block;
            background: rgba(221,132,72,0.15);
            color: #ffb07a;
            border: 1px solid rgba(221,132,72,0.35);
            padding: 2px 8px;
            border-radius: 999px;
            font-size: 12px;
            margin-left: 8px;
        }
        .list { margin: 0; padding-left: 18px; color: #b0b0b0; }
        .list li { margin-bottom: 6px; }
        .summary {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 16px;
            margin-bottom: 24px;
        }
        .callout {
            background: #202020;
            border: 1px dashed #3a3a3a;
            border-radius: 10px;
            padding: 14px;
            color: #a9a9a9;
        }
        .kpi {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(160px, 1fr));
            gap: 10px;
        }
        .kpi .item {
            background: #1c1c1c;
            border: 1px solid #2a2a2a;
            border-radius: 10px;
            padding: 10px 12px;
        }
        .kpi .label { color: #8e8e8e; font-size: 12px; }
        .kpi .value { color: #ffffff; font-weight: 700; font-size: 18px; }
        .muted { color: #9a9a9a; }
        .accent { color: #dd8448; }
    </style>
</head>
<body>
    <div class="sidebar"></div>
    <div class="main-content">
        <h1 class="title">t-SNE Overview <span class="badge">Guide</span></h1>
        <div class="subtitle">t-Distributed Stochastic Neighbor Embedding: probabilistic dimensionality reduction that preserves local neighborhoods using Student t-distribution in low-dimensional space.</div>

        <div class="grid">
            <div class="card">
                <h3>Primary Uses</h3>
                <p>Data visualization, exploratory data analysis, clustering visualization, preserving local structure, non-linear dimensionality reduction, high-dimensional data exploration, single-cell RNA-seq analysis.</p>
            </div>
            <div class="card">
                <h3>Strengths</h3>
                <p>Excellent for visualization, preserves local neighborhoods well, reveals clusters and structure, handles non-linear relationships, probabilistic framework, widely used and well-understood.</p>
            </div>
            <div class="card">
                <h3>Watch-outs</h3>
                <p>Computationally expensive (O(n²)), non-deterministic (different runs give different results), does not preserve global structure, sensitive to perplexity parameter, cannot transform new data points, memory intensive.</p>
            </div>
        </div>

        <div class="section">
            <h2>How It Works <span class="badge">Mathematical Foundation</span></h2>
            <div class="summary">
                <div>
                    <p class="muted"><span class="accent">t-SNE</span> converts high-dimensional Euclidean distances between data points into conditional probabilities that represent similarities. It then finds a low-dimensional embedding where these probabilities are best preserved using a Student t-distribution, which has heavier tails than Gaussian, allowing better separation of clusters.</p>
                    <ul class="list">
                        <li><strong>High-Dimensional Probabilities:</strong> For each point <em>i</em>, compute conditional probability <em>p<sub>j|i</sub></em> that point <em>j</em> would be chosen as neighbor: <em>p<sub>j|i</sub> = exp(-‖x<sub>i</sub> − x<sub>j</sub>‖² / 2σ<sub>i</sub>²) / Σ<sub>k≠i</sub> exp(-‖x<sub>i</sub> − x<sub>k</sub>‖² / 2σ<sub>i</sub>²)</em>.</li>
                        <li><strong>Perplexity:</strong> Parameter that controls effective number of neighbors. For each point, σ<sub>i</sub> is chosen so that perplexity <em>Perp(P<sub>i</sub>) = 2<sup>H(P<sub>i</sub>)</sup></em> matches target (typically 5-50).</li>
                        <li><strong>Symmetric Probabilities:</strong> Compute joint probabilities <em>p<sub>ij</sub> = (p<sub>j|i</sub> + p<sub>i|j</sub>) / 2n</em>.</li>
                        <li><strong>Low-Dimensional Probabilities:</strong> In embedding space, use Student t-distribution: <em>q<sub>ij</sub> = (1 + ‖y<sub>i</sub> − y<sub>j</sub>‖²)<sup>-1</sup> / Σ<sub>k≠l</sub> (1 + ‖y<sub>k</sub> − y<sub>l</sub>‖²)<sup>-1</sup></em>.</li>
                        <li><strong>KL Divergence:</strong> Minimize <em>C = Σ<sub>ij</sub> p<sub>ij</sub> log(p<sub>ij</sub> / q<sub>ij</sub>)</em> using gradient descent.</li>
                        <li><strong>Gradient:</strong> <em>∂C/∂y<sub>i</sub> = 4Σ<sub>j</sub> (p<sub>ij</sub> − q<sub>ij</sub>)(y<sub>i</sub> − y<sub>j</sub>)(1 + ‖y<sub>i</sub> − y<sub>j</sub>‖²)<sup>-1</sup></em>.</li>
                        <li><strong>Momentum:</strong> Uses momentum and early exaggeration to escape local minima and improve convergence.</li>
                    </ul>
                </div>
                <div class="callout">Tip: Perplexity balances local vs global structure. Low perplexity (5-15) emphasizes local structure; high perplexity (30-50) considers more neighbors. Start with perplexity ≈ 30. Learning rate typically 200-1000; use early exaggeration (×12) for first iterations to help clusters separate.</div>
            </div>
        </div>

        <div class="section">
            <h2>Dimensionality Reduction Statistics <span class="badge">Interpretation</span></h2>
            <div class="kpi">
                <div class="item"><div class="label">Original Dimensions</div><div class="value">Input feature count</div></div>
                <div class="item"><div class="label">Reduced Dimensions</div><div class="value">Embedding size (typically 2-3)</div></div>
                <div class="item"><div class="label">KL Divergence</div><div class="value">Final cost (lower = better)</div></div>
                <div class="item"><div class="label">Perplexity</div><div class="value">Effective neighbors per point</div></div>
                <div class="item"><div class="label">Compression Ratio</div><div class="value">Original dims / reduced dims</div></div>
            </div>
        </div>

        <div class="section">
            <h2>Reading the Visualizations <span class="badge">Analysis</span></h2>
            <ul class="list">
                <li><strong>2D Embedding Plot:</strong> Visualize clusters and local structure; similar points should be close, but distances are not meaningful.</li>
                <li><strong>KL Divergence History:</strong> Monitor convergence; should decrease and stabilize. Large jumps indicate instability.</li>
                <li><strong>Perplexity Effect:</strong> Compare embeddings with different perplexity values to see how it affects local vs global structure.</li>
                <li><strong>Cluster Separation:</strong> Well-separated clusters indicate good local structure preservation.</li>
                <li><strong>Iteration Progress:</strong> Watch how embedding evolves; early exaggeration phase should show rapid cluster separation.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Parameter Guidance <span class="badge">Best Practice</span></h2>
            <ul class="list">
                <li><strong>Perplexity:</strong> Typically 5-50. Start with 30. Lower = more local structure, higher = more global structure. Should be less than number of samples.</li>
                <li><strong>Learning Rate:</strong> Typically 200-1000. Too low = slow convergence, too high = instability. Start with 200.</li>
                <li><strong>Iterations:</strong> Typically 1000-5000. More iterations = better convergence but slower. Monitor KL divergence.</li>
                <li><strong>Early Exaggeration:</strong> Typically 12. Multiplies p<sub>ij</sub> in early iterations to help clusters separate. Use for first ~250 iterations.</li>
                <li><strong>Embedding Dimension:</strong> Usually 2-3 for visualization. Higher dimensions preserve more structure but harder to visualize.</li>
                <li><strong>Normalization:</strong> Standardize features before t-SNE to treat all dimensions uniformly.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Data Preparation <span class="badge">Checklist</span></h2>
            <ul class="list">
                <li>Normalize or standardize features (critical for distance-based probabilities).</li>
                <li>Ensure sufficient sample size—t-SNE works best with hundreds to thousands of samples.</li>
                <li>Impute or remove missing values—distance computation requires complete data.</li>
                <li>Consider dimensionality reduction (e.g., PCA) before t-SNE for very high-dimensional data to reduce noise.</li>
                <li>Remove outliers that could distort probability distributions.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Common Pitfalls <span class="badge">Avoid</span></h2>
            <ul class="list">
                <li><strong>Perplexity too low:</strong> Emphasizes very local structure; embedding becomes fragmented.</li>
                <li><strong>Perplexity too high:</strong> Considers too many neighbors; loses local structure, approaches PCA-like behavior.</li>
                <li><strong>Learning rate too high:</strong> Embedding becomes unstable, clusters may not form properly.</li>
                <li><strong>Too few iterations:</strong> Embedding may not converge; clusters not well-separated.</li>
                <li><strong>Interpreting distances:</strong> Distances in t-SNE embedding are not meaningful; only local neighborhoods matter.</li>
                <li><strong>Using for new data:</strong> t-SNE cannot transform new points; must re-run on full dataset.</li>
            </ul>
        </div>

        <div class="section">
            <h2>When to Use <span class="badge">Application</span></h2>
            <ul class="list">
                <li>Visualizing high-dimensional data to reveal clusters and structure.</li>
                <li>Exploratory data analysis when you want to see local neighborhoods.</li>
                <li>Single-cell RNA-seq and other high-dimensional biological data visualization.</li>
                <li>When global structure preservation is not critical.</li>
                <li>As a visualization tool for clustering results.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Alternatives to Consider <span class="badge">Comparison</span></h2>
            <ul class="list">
                <li><strong>UMAP:</strong> Faster, preserves more global structure, can transform new points.</li>
                <li><strong>PCA:</strong> Much faster, preserves global structure, but only linear relationships.</li>
                <li><strong>Isomap:</strong> Preserves geodesic distances; better for manifold unfolding.</li>
                <li><strong>LLE:</strong> Preserves local linear relationships; faster than t-SNE.</li>
                <li><strong>Autoencoders:</strong> Can transform new points, but requires training.</li>
            </ul>
        </div>
    </div>
    <script src="../sidebar.js"></script>
</body>
</html>

