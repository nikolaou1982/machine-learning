<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Learn about RFE, a dimensionality reduction method. Comprehensive overview with theory, applications, and use cases for machine learning and data science.">
  <link rel="canonical" href="https://yourdomain.com/Dimensionality_Reduction/RFE_Overview.html">
  <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "name": "RFE - Overview & Theory | Dimensionality Reduction | ML Tools",
  "description": "Learn about RFE, a dimensionality reduction method. Comprehensive overview with theory, applications, and use cases for machine learning and data science.",
  "url": "https://yourdomain.com/Dimensionality_Reduction/RFE_Overview.html",
  "about": {
    "@type": "Thing",
    "name": "RFE",
    "description": "RFE algorithm for dimensionality reduction"
  },
  "headline": "RFE",
  "articleSection": "Dimensionality Reduction"
}
  </script>
    <title>RFE - Overview & Theory | Dimensionality Reduction | ML Tools</title>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@200;300;400;600;700;800;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Nunito', sans-serif;
            color: #cfcfcf;
            background-color: #1e1e1e;
            margin: 0;
            padding: 0;
            display: flex;
            min-height: 100vh;
        }
        .sidebar {
            width: 250px;
            background-color: #171717;
            padding: 30px 20px;
            border-right: 1px solid #333;
            overflow-y: auto;
            height: 100vh;
        }
        .sidebar h1 { color: white; font-size: 1.8rem; font-weight: bold; margin-bottom: 30px; text-align: center; }
        .nav-section { margin-bottom: 30px; }
        .nav-section h3 { color: #dd8448; font-size: 0.9rem; font-weight: 600; text-transform: uppercase; margin-bottom: 15px; letter-spacing: 1px; }
        .nav-item { display: block; color: #676767; text-decoration: none; padding: 12px 15px; margin-bottom: 5px; border-radius: 8px; transition: all 0.3s ease; font-weight: 500; }
        .nav-item:hover { background-color: #2d2d2d; color: white; transform: translateX(5px); }
        .nav-item.active { background-color: #dd8448; color: white; }
        .nav-category { margin-bottom: 20px; }
        .nav-category-header { color: #dd8448; font-size: 0.85rem; font-weight: 600; text-transform: uppercase; padding: 10px 15px; cursor: pointer; border-radius: 8px; transition: background-color 0.3s ease; display: flex; justify-content: space-between; align-items: center; letter-spacing: 1px; }
        .nav-category-header:hover { background-color: #2d2d2d; }
        .nav-category-header .arrow { transition: transform 0.3s ease; font-size: 0.7rem; }
        .nav-category-header.collapsed .arrow { transform: rotate(-90deg); }
        .nav-subcategory { margin-left: 15px; margin-top: 10px; overflow: hidden; max-height: 1200px; transition: max-height 0.3s ease; }
        .nav-subcategory.collapsed { max-height: 0; }
        .nav-subheader { color: #999; font-size: 0.75rem; font-weight: 600; text-transform: uppercase; padding: 8px 15px; margin-top: 5px; letter-spacing: 0.5px; cursor: pointer; display: flex; justify-content: space-between; align-items: center; border-radius: 6px; transition: background-color 0.3s ease; }
        .nav-subheader:hover { background-color: #2d2d2d; }
        .nav-subheader .arrow { font-size: 0.6rem; transition: transform 0.3s ease; }
        .nav-subheader.collapsed .arrow { transform: rotate(-90deg); }
        .nav-subheader.category-header { color: #dd8448; font-size: 0.85rem; font-weight: 700; padding: 10px 15px; margin-top: 8px; letter-spacing: 1px; border: 1px solid rgba(221,132,72,0.3); }
        .nav-subheader.category-header:hover { background-color: rgba(221,132,72,0.15); border-color: rgba(221,132,72,0.5); }
        .nav-subgroup { overflow: hidden; max-height: 200px; transition: max-height 0.3s ease; padding-bottom: 5px; }
        .nav-subgroup.collapsed { max-height: 0; }
        .nav-subgroup.category-group { max-height: 1000px; }
        .nav-subgroup.category-group.collapsed { max-height: 0; }
        .nav-subheader.nested { margin-left: 10px; font-size: 0.7rem; }
        .nav-subgroup.nested { margin-left: 10px; max-height: 200px; }
        .nav-subheader.subcategory-header { color: #999; font-size: 0.75rem; font-weight: 600; padding: 8px 15px; margin-left: 10px; margin-top: 5px; letter-spacing: 0.5px; border: 1px solid rgba(153, 153, 153, 0.2); }
        .nav-subheader.subcategory-header:hover { background-color: rgba(45, 45, 45, 0.5); border-color: rgba(153, 153, 153, 0.4); }
        .nav-subgroup.subcategory-group { margin-left: 10px; max-height: 2000px; overflow: hidden; transition: max-height 0.3s ease; padding-bottom: 5px; }
        .nav-subgroup.subcategory-group.collapsed { max-height: 0; }
        .nav-item.sub { padding: 8px 15px; font-size: 0.9rem; margin-left: 10px; margin-bottom: 5px; }
        .main-content {
            flex: 1;
            padding: 40px;
        }
        .title {
            color: #ffffff;
            font-size: 2.2rem;
            font-weight: 800;
            margin: 0 0 8px 0;
        }
        .subtitle {
            color: #8a8a8a;
            font-size: 1rem;
            margin-bottom: 28px;
        }
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 20px;
            margin-bottom: 28px;
        }
        .card {
            background-color: #171717;
            border: 1px solid #333;
            border-radius: 12px;
            padding: 22px;
            transition: border-color 0.3s ease, transform 0.3s ease;
        }
        .card:hover { border-color: #dd8448; transform: translateY(-3px); }
        .card h3 { color: #ffffff; margin: 0 0 8px 0; font-size: 1.15rem; }
        .card p { color: #9a9a9a; margin: 0; line-height: 1.6; }
        .section {
            background-color: #171717;
            border: 1px solid #333;
            border-radius: 12px;
            padding: 24px;
            margin-bottom: 24px;
        }
        .section h2 {
            color: #ffffff;
            font-size: 1.5rem;
            margin: 0 0 12px 0;
        }
        .badge {
            display: inline-block;
            background: rgba(221,132,72,0.15);
            color: #ffb07a;
            border: 1px solid rgba(221,132,72,0.35);
            padding: 2px 8px;
            border-radius: 999px;
            font-size: 12px;
            margin-left: 8px;
        }
        .list { margin: 0; padding-left: 18px; color: #b0b0b0; }
        .list li { margin-bottom: 6px; }
        .split {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 16px;
        }
        .callout {
            background: #202020;
            border: 1px dashed #3a3a3a;
            border-radius: 10px;
            padding: 14px;
            color: #a9a9a9;
        }
        .kpi {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(160px, 1fr));
            gap: 10px;
        }
        .kpi .item {
            background: #1c1c1c;
            border: 1px solid #2a2a2a;
            border-radius: 10px;
            padding: 10px 12px;
        }
        .kpi .label { color: #8e8e8e; font-size: 12px; }
        .kpi .value { color: #ffffff; font-weight: 700; font-size: 18px; }
        .muted { color: #9a9a9a; }
        .accent { color: #dd8448; }
    </style>
</head>
<body>
    <div class="sidebar"></div>
    <div class="main-content">
        <h1 class="title">Recursive Feature Elimination (RFE) Overview <span class="badge">Guide</span></h1>
        <div class="subtitle">A wrapper method that recursively removes features based on model coefficients/importance — faster than Forward/Backward Elimination by using feature rankings instead of cross-validation.</div>

        <div class="grid">
            <div class="card">
                <h3>Primary Uses</h3>
                <p>Finding optimal feature subsets for supervised learning, model-aware feature selection, handling feature interactions, improving model performance, reducing overfitting, efficient feature elimination based on model coefficients.</p>
            </div>
            <div class="card">
                <h3>Strengths</h3>
                <p>Faster than Forward/Backward Elimination (uses coefficients, not CV), model-aware (considers actual model importance), handles feature interactions, finds optimal feature combinations, interpretable elimination process, can remove multiple features per step, works with any model that provides feature importance.</p>
            </div>
            <div class="card">
                <h3>Watch-outs</h3>
                <p>Requires target variable (supervised only), sensitive to model choice, may overfit with small datasets, greedy approach may miss optimal combinations, coefficient-based ranking may not reflect true importance, slower than filter methods, requires model that provides feature importance.</p>
            </div>
        </div>

        <div class="section">
            <h2>How It Works <span class="badge">Mathematical Foundation</span></h2>
            <div class="split">
                <div>
                    <p class="muted">Recursive Feature Elimination (RFE) is a <span class="accent">wrapper method</span> that recursively removes features based on their importance scores (e.g., absolute coefficients). It trains a model, ranks features by importance, removes the least important features, and repeats until the desired number of features is reached.</p>
                    <ul class="list">
                        <li><strong>Initialization</strong>: Start with all features S = {all features}. The algorithm will remove features from S recursively.</li>
                        <li><strong>Model Training</strong>: Train a model (e.g., linear regression, logistic regression) on the current feature set S.</li>
                        <li><strong>Feature Ranking</strong>: Rank features by their importance scores. For linear models, use absolute coefficients |w_i|. For other models, use feature importance scores.</li>
                        <li><strong>Feature Elimination</strong>: Remove the least important features (typically one or a small number per iteration).</li>
                        <li><strong>Recursion</strong>: Repeat steps 2-4 until the desired number of features is reached.</li>
                        <li><strong>Efficiency</strong>: RFE is faster than Forward/Backward Elimination because it uses model coefficients instead of cross-validation, but may be less accurate.</li>
                    </ul>
                </div>
                <div class="callout">Tip: RFE is particularly useful when you want a faster alternative to Forward/Backward Elimination. It uses model coefficients to rank features, making it more efficient but potentially less accurate than methods that use cross-validation. Use it when you have a moderate number of features (e.g., 10-100) and want to quickly identify important features.</div>
            </div>
        </div>

        <div class="section">
            <h2>Feature Selection Statistics <span class="badge">Interpretation</span></h2>
            <div class="kpi">
                <div class="item"><div class="label">Original Features</div><div class="value">Number of input features</div></div>
                <div class="item"><div class="label">Selected Features</div><div class="value">Number of features in optimal subset</div></div>
                <div class="item"><div class="label">Elimination Order</div><div class="value">Order in which features were removed</div></div>
                <div class="item"><div class="label">Feature Rankings</div><div class="value">Importance scores at each iteration</div></div>
                <div class="item"><div class="label">Iterations</div><div class="value">Number of elimination iterations</div></div>
                <div class="item"><div class="label">Features per Step</div><div class="value">Number of features removed per iteration</div></div>
            </div>
        </div>

        <div class="section">
            <h2>Reading the Visualizations <span class="badge">Analysis</span></h2>
            <ul class="list">
                <li><strong>Feature Rankings</strong>: Bar chart showing feature importance scores (absolute coefficients) at each iteration. Helps identify which features are most/least important.</li>
                <li><strong>Elimination History</strong>: Shows which features were removed at each iteration and their importance scores. Helps understand the elimination process.</li>
                <li><strong>Feature Importance Over Time</strong>: Line plot showing how feature importance changes as features are removed. Helps identify stable important features.</li>
                <li><strong>Coefficient Heatmap</strong>: Heatmap showing feature coefficients across iterations. Helps visualize how feature importance evolves.</li>
                <li><strong>Elimination Order</strong>: Bar chart showing features in elimination order. Features removed first are least important.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Parameter Guidance <span class="badge">Best Practice</span></h2>
            <ul class="list">
                <li><strong>N Features</strong>: Number of features to select. Common values: 5-20 for moderate datasets. Use cross-validation to find optimal number.</li>
                <li><strong>Step</strong>: Number of features to remove per iteration. Common values: 1 (most thorough) or 2-5 (faster). Use 1 for small feature sets, larger values for speed.</li>
                <li><strong>Model Type</strong>: Base model for evaluation. Linear regression for regression, logistic regression for classification. Choose based on your task.</li>
                <li><strong>Scoring Metric</strong>: Metric for evaluation (optional, for RFE with CV). R² for regression, accuracy/F1 for classification.</li>
                <li><strong>Use Absolute Coefficients</strong>: Whether to use absolute values of coefficients for ranking. Recommended: Yes (default).</li>
            </ul>
        </div>

        <div class="section">
            <h2>Data Preparation <span class="badge">Best Practice</span></h2>
            <ul class="list">
                <li><strong>Handle Missing Values</strong>: Remove or impute missing values before feature selection. RFE requires complete data.</li>
                <li><strong>Standardize Features</strong>: Standardize features (mean=0, std=1) for models like linear/logistic regression. This ensures fair comparison of coefficients.</li>
                <li><strong>Target Variable</strong>: RFE requires a target variable (supervised learning). Ensure target is properly encoded (numeric for regression, categorical for classification).</li>
                <li><strong>Sample Size</strong>: RFE works best with moderate to large sample sizes (n > 50). For small datasets, use fewer features or consider simpler methods.</li>
                <li><strong>Feature Scaling</strong>: Scale features to similar ranges to ensure fair coefficient comparison. Use standardization or normalization.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Common Pitfalls <span class="badge">Avoid</span></h2>
            <ul class="list">
                <li><strong>Too Few Features</strong>: Selecting too few features can lead to underfitting. Use cross-validation to find the optimal number.</li>
                <li><strong>Too Large Step</strong>: Removing too many features per step can skip optimal subsets. Use step=1 for thorough search, larger values only for speed.</li>
                <li><strong>Ignoring Feature Interactions</strong>: RFE may miss important feature interactions if features are evaluated individually. Consider polynomial features or interaction terms.</li>
                <li><strong>Not Standardizing</strong>: Not standardizing features can bias ranking toward features with larger scales. Always standardize before selection.</li>
                <li><strong>Wrong Model Type</strong>: Using regression model for classification (or vice versa) will give meaningless results. Match model type to task.</li>
                <li><strong>Coefficient Interpretation</strong>: Coefficients may not reflect true feature importance, especially with correlated features. Use caution when interpreting rankings.</li>
                <li><strong>Overfitting</strong>: RFE can overfit if used without proper validation. Use cross-validation or hold-out set for final evaluation.</li>
            </ul>
        </div>

        <div class="section">
            <h2>When to Use <span class="badge">Application</span></h2>
            <ul class="list">
                <li><strong>Faster Alternative to Forward/Backward</strong>: When you want model-aware selection but need faster execution than Forward/Backward Elimination.</li>
                <li><strong>Moderate Feature Count</strong>: When you have a moderate number of features (10-100) and want to quickly identify important features.</li>
                <li><strong>Supervised Learning</strong>: When you have a target variable and want to select features that improve prediction performance.</li>
                <li><strong>Model-Specific Selection</strong>: When you have a specific model in mind and want to find the best feature subset for that model.</li>
                <li><strong>Feature Interactions</strong>: When features may interact and you want to capture these interactions through model coefficients.</li>
                <li><strong>Interpretable Elimination</strong>: When you want to understand which features contribute least to model performance based on coefficients.</li>
                <li><strong>Large Datasets</strong>: When you have large datasets and Forward/Backward Elimination is too slow.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Alternatives to Consider <span class="badge">Comparison</span></h2>
            <ul class="list">
                <li><strong>vs Forward Selection</strong>: RFE is faster (uses coefficients) but may be less accurate. Forward Selection uses CV but is slower. Use RFE for speed, Forward Selection for accuracy.</li>
                <li><strong>vs Backward Elimination</strong>: RFE is faster (uses coefficients) but may be less accurate. Backward Elimination uses CV but is slower. Use RFE for speed, Backward Elimination for accuracy.</li>
                <li><strong>vs Filter Methods</strong>: RFE is model-aware but slower. Filter methods are fast but model-agnostic. Use RFE for model-specific selection, filter methods for quick ranking.</li>
                <li><strong>vs Embedded Methods (e.g., Lasso)</strong>: Embedded methods perform selection during training, RFE is separate. Embedded methods are faster, RFE is more flexible.</li>
                <li><strong>vs Mutual Information</strong>: Mutual Information is fast but doesn't consider model performance. RFE is slower but model-aware. Use Mutual Information for quick ranking, RFE for final selection.</li>
                <li><strong>vs RFE with CV</strong>: Standard RFE uses coefficients, RFE with CV uses cross-validation. RFE with CV is more accurate but slower. Use standard RFE for speed, RFE with CV for accuracy.</li>
            </ul>
        </div>
    </div>
    <script src="../sidebar.js"></script>
</body>
</html>


